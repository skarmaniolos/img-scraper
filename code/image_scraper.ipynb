{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scraper for Online Image Boards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from re import sub, finditer\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gets images from URL and saves to destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dest_dir, filename=None):\n",
    "    if(filename is None):\n",
    "        filename = urlsplit(url).path.split(\"/\")[-1]\n",
    "        \n",
    "    request = requests.get(url)\n",
    "    image = Image.open(BytesIO(request.content))\n",
    "    \n",
    "    if image.mode in ('RGBA', 'LA'):\n",
    "        #background = Image.new(image.mode[:-1], image.size, fill_color)\n",
    "        #background.paste(image, image.split()[-1])\n",
    "        background = img_alpha_to_colour(image)\n",
    "        image = background\n",
    "    \n",
    "    image.save(os.path.join(dest_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handles images that have no alpha layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_alpha_to_colour(image, color=(255, 255, 255)):\n",
    "    image.load()  # needed for split()\n",
    "    background = Image.new('RGB', image.size, color)\n",
    "    background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takes HTML code as input, creates list, appends img elements to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_urls(soup):\n",
    "    file_urls = []\n",
    "    \n",
    "    # fix href errors\n",
    "    for anchor in soup.find_all(attrs={'class':'fileThumb'}):\n",
    "        file_urls.append(sub(\"//\", \"https://\", anchor.get('href')))\n",
    "    return file_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate through posts, find img filenames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(soup):\n",
    "    filenames = []\n",
    "\n",
    "    for anchor in soup.find_all(attrs={'class': 'fileText'}):\n",
    "        filenames.append(anchor.get_text().split(\" \")[1])\n",
    "        print(filenames.append(anchor.get_text().split(\" \")[1]))\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url):\n",
    "    print(\"┌─────────────────────────────────────────────────────────────────────┐\")\n",
    "    print(\"│           Image Scraping Tool built by Steven Karmaniolos           │\")\n",
    "    print(\"└─────────────────────────────────────────────────────────────────────┘\")\n",
    "    print(\"Downloading images from \" + url + \" ...\")\n",
    "    \n",
    "    dest_dir = os.getcwd()\n",
    "    \n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    file_urls = get_file_urls(soup)\n",
    "    filenames = get_filenames(soup)\n",
    "\n",
    "    for i in range(len(file_urls)):\n",
    "        print(\"Downloading file: \" + filenames[i])\n",
    "        download_file(file_urls[i], dest_dir, filenames[i])\n",
    "\n",
    "    print(\"┌─────────────────────────────────────────────────────────────────────┐\")\n",
    "    print(\"│             Scrape completed. Your files are now ready.             │\")\n",
    "    print(\"└─────────────────────────────────────────────────────────────────────┘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────────────────────────────────────┐\n",
      "│           Image Scraping Tool built by Steven Karmaniolos           │\n",
      "└─────────────────────────────────────────────────────────────────────┘\n",
      "Downloading images from http://boards.4channel.org/v/thread/458971715 ...\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "Downloading file: switch.jpg\n",
      "Downloading file: switch.jpg\n",
      "Downloading file: 1554934817237.png\n",
      "Downloading file: 1554934817237.png\n",
      "┌─────────────────────────────────────────────────────────────────────┐\n",
      "│             Scrape completed. Your files are now ready.             │\n",
      "└─────────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "main(\"http://boards.4channel.org/v/thread/458971715\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
